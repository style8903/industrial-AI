# -*- coding: utf-8 -*-
"""2. dnn_mnist_classification_배포.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iCjDwcUP61D-ZhmMVb9svnssKCo4JaIk

- https://www.tensorflow.org/api_docs/python/tf

## step 1. 데이터 준비
"""

# import 
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt   # 시각화

# dataset 로드 

(train_images ,train_labels ), (test_images, test_labels) = mnist.load_data()

# 탐색- shape, 건수, 값 
train_images.shape

train_labels.shape

train_images[0]  # 28*28  0:검은색 ,  255:흰색

train_labels

# test_images 의 샘플 수?
test_images.shape

# train_images[0] 이미지

plt.figure()
plt.imshow(train_images[9])  # 이미지 show
plt.colorbar()
# plt.grid(True)
plt.show()



"""## step 2. 전처리"""

# 1. image data(28*28) 를 1차원 텐서로 변환
# reshape, 왜? Dense layer - flatten

train_images.shape

train_images = train_images.reshape(60000, 28*28)
test_images = test_images.reshape(10000, 28*28)

train_images.shape

# 2. label을 encoding : one-hot encoding
train_labels
# label encoding
# one-hot encoding
# tv, 냉장고, 컴퓨터 => 숫자 label 1,2,3 => one-hot encoding
# 0~9 10개 
# train, test = label

# 0 : [1,0,0,0,0,0,0,0,0,0]
# 1 : [0,1,0,0,0,0,0,0,0,0]
# 9 : [0,0,0,0,0,0,0,0,0,1]

from tensorflow.keras.utils import to_categorical

train_labels = to_categorical(train_labels)  # 
test_labels = to_categorical(test_labels)

train_labels.shape

train_labels[0]

"""## step 3. 모델 만들기"""

from tensorflow.keras import models, layers

model = models.Sequential()
# model.add(layers.Input(shape=(28*28,))) # 추가해도 됨
# model.add(layers.Flatten())      # reshape 1차원
model.add(layers.Dense(units=512,
                       activation='relu',
                       input_shape=(28*28,)))
model.add(layers.Dense(units=10 , activation='softmax'))
# 0~9 분류 10 , 확률값

model.summary()

# weight, bias 갯수
# input layer feature 수?  784
# hidden layer units ? 512
# hidden layer  : w = 784 * 512 b = 512 

# output layer parameter 갯수 식 : 512*10+10

"""## step 4. 손실함수, 옵티마이저, 성능지표 선택"""

model.compile(optimizer='rmsprop',  # 경사하강법
              loss='categorical_crossentropy',  # 예측값이 확률로 나올때, target 이 one-hot
              metrics=['accuracy'])

"""## step 5. fit"""

60000*0.8 / 128

# [문제] 샘플수 100건, 에폭 1, batch_size = 10 
# 웨이트는 몇 번 업데이트되나요?
# 샘플수 100건, 에폭 3, batch_size = 10
# 웨이트는 몇 번 업데이트되나요? 30

history = model.fit(train_images, train_labels,
                    epochs=30, 
                    batch_size=128,   # step
                    validation_split=0.2)

"""## step 6. 훈련과정 시각화"""

history.history.keys()

loss = history.history['loss']
val_loss = history.history['val_loss']

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

epochs = range(len(acc))

acc

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.legend()
plt.show()

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

"""## step 7. 평가"""

test_loss, test_acc = model.evaluate(test_images, test_labels)

model.save('/content/drive/My Drive/Colab Notebooks/11 시각지능/mnist_model.h5')

new_model = models.load_model('./mnist_model.h5')

new_model.summary()

from google.colab import drive
drive.mount('/content/drive')

"""## step 8. 예측하기"""

import numpy as np
# predict = model.predict(test_images[].reshape(1,784)) 
# predict = model.predict(test_images[len(test_images) - 1].reshape(1,28*28))
predict = model.predict(test_images[-1].reshape(1,28*28))

print('predict probability:', predict)   # softmax
print('predict number:', np.argmax(predict))

np.argmax(predict)  # max 값의 index 출력하라

test_images[0].shape

# 예측한 값이 실제 값과 맞는지 확인해주세요
test_labels[0]

# 실제 값을 이미지 출력해주세요.

plt.figure()
plt.imshow(test_images[-1].reshape(28,28))  # 이미지 show
plt.colorbar()
plt.show()

# test_images 마지막 이미지 predict -> 실제값 이미지 출력 
# 숫자? 채팅창에~